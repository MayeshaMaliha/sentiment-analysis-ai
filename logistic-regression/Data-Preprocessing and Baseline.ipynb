{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f2d95e",
   "metadata": {},
   "source": [
    "## Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388ed281",
   "metadata": {},
   "source": [
    "pandas as pd: For data manipulation and analysis (e.g., load, clean, and analyze tabular data).\n",
    "\n",
    "re: For text pattern matching using regular expressions (e.g., find emails, replace text).\n",
    "\n",
    "nltk.corpus import stopwords: Removes common words (e.g., \"the\", \"is\") during text preprocessing in NLP tasks.\n",
    "\n",
    "TfidfVectorizer: Converts text to numerical features for machine learning by measuring word importance.\n",
    "\n",
    "os: Interacts with the operating system (e.g., file handling, environment variables).\n",
    "\n",
    "nltk: For NLP tasks like tokenization, stemming, and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8aaaa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mayeshamalihaproma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to: processed_data/imdb_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# File path for the dataset\n",
    "file_path = 'IMDB Dataset.csv'  # File is in the same directory as the notebook\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a directory for processed data if it doesn't exist\n",
    "os.makedirs('processed_data', exist_ok=True)\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stop words (optional)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to the review column\n",
    "data['cleaned_review'] = data['review'].apply(clean_text)\n",
    "\n",
    "# Vectorize the text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to top 5000 words\n",
    "X = vectorizer.fit_transform(data['cleaned_review']).toarray()\n",
    "\n",
    "# Save processed data\n",
    "processed_data = pd.DataFrame(X, columns=vectorizer.get_feature_names_out())\n",
    "processed_data['sentiment'] = data['sentiment']\n",
    "\n",
    "# Save processed data to CSV\n",
    "output_path = 'processed_data/imdb_processed.csv'\n",
    "processed_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Preprocessed data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a33f6",
   "metadata": {},
   "source": [
    "## Load the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d00e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaron  abandoned  abc  abilities  ability  able  absence  absent  absolute  \\\n",
       "0    0.0        0.0  0.0        0.0      0.0   0.0      0.0     0.0       0.0   \n",
       "1    0.0        0.0  0.0        0.0      0.0   0.0      0.0     0.0       0.0   \n",
       "2    0.0        0.0  0.0        0.0      0.0   0.0      0.0     0.0       0.0   \n",
       "3    0.0        0.0  0.0        0.0      0.0   0.0      0.0     0.0       0.0   \n",
       "4    0.0        0.0  0.0        0.0      0.0   0.0      0.0     0.0       0.0   \n",
       "\n",
       "   absolutely  ...     young  younger     youre  youth  youve  zero    zombie  \\\n",
       "0         0.0  ...  0.000000      0.0  0.000000    0.0    0.0   0.0  0.000000   \n",
       "1         0.0  ...  0.000000      0.0  0.000000    0.0    0.0   0.0  0.000000   \n",
       "2         0.0  ...  0.079299      0.0  0.000000    0.0    0.0   0.0  0.000000   \n",
       "3         0.0  ...  0.000000      0.0  0.079664    0.0    0.0   0.0  0.117844   \n",
       "4         0.0  ...  0.000000      0.0  0.000000    0.0    0.0   0.0  0.000000   \n",
       "\n",
       "   zombies  zone  sentiment  \n",
       "0      0.0   0.0   positive  \n",
       "1      0.0   0.0   positive  \n",
       "2      0.0   0.0   positive  \n",
       "3      0.0   0.0   negative  \n",
       "4      0.0   0.0   positive  \n",
       "\n",
       "[5 rows x 5001 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('processed_data/imdb_processed.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b28c1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features (X) and Labels (y)\n",
    "X = processed_data.drop(columns=['sentiment'])\n",
    "y = processed_data['sentiment']\n",
    "\n",
    "# Encode labels (convert positive/negative to 1/0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2797b978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8867\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      4961\n",
      "           1       0.88      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
